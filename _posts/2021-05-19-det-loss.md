---
layout: post
title:  "[Det] Loss Functions"
date:   2021-05-19 09:00:13
categories: 2021-1-detector
---



## 1. Detector Loss

손실 함수(loss function)란 모델의 출력(예측, Prediction)과 Ground Truth(GT, Annotation, Label) 사이의 차이를 나타내는 함수다. 모델 학습은 이 손실 함수를 줄이기 위해 신경망의 파라미터들을 업데이트 한다. 모델 예측과 GT 사이의 직접적인 차이를 손실함수로 쓸 수도 있지만 (e.g. $||x-y||, ||x-y||^2$) Cross Entropy처럼 간접적으로 둘 사이의 차이에 비례하여 커지는 다른 함수를 사용할 수도 있다. 

Object Detector는 검출, 분류, 회귀(regression) 세 가지 기능을 하고 세 가지 예측이 모두 맞아야 객체를 제대로 찾을 수 있다. 따라서 손실 함수가 하나의 함수로 이뤄지지 않고 여러 손실 함수의 합으로 전체 손실 함수가 만들어진다. 다음은 Object Detector의 세 가지 기능에 대한 설명이다.

- 검출: 모델이 출력한 multi-scale feature map에서 scale × grid_h × grid_w × anchor 마다 객체가 있는지 없는지 **Objectness**를 구분한다. Objectness는 0~1 사이의 확률값으로 출력한다.
- 분류: 모델에서 출력된 객체마다 객체의 종류를 분류한다. 각 객체 출력은 K(카테고리 개수) 차원의 **Categorical Probability**를 포함한다.
- 회귀: 검출 모델은 객체를 감싸는 **Bounding Box**를 예측한다. Bounding Box는 위치(y, x)와 크기(h, w)로 나타내는데 이미지 너비, 높이를 1로 가정하여 위치와 크기를 0~1 사이의 값으로 출력한다.

이제 각각의 기능을 학습시키는 다양한 손실 함수에 대해서 알아보자. 같은 기능을 학습시켜도 논문마다 다양한 손실 함수를 제안하고 있으니 여러가지를 시도해보는게 좋다.

### 1.1. Bounding Box

> y, x: bounding box 중심점 좌표
>
> h, w: bounding box 높이, 너비
>
> o: objectness
>
> $G_h, G_w, A$: feature grid map 높이, 너비, anchor 개수
>
> **GT**: $y^*, x^*, h^*, w^* \in [0, 1]$
>
> **Prediction**: $y^*, x^*, h^*, w^* \in [0, 1]$
>
> **Anchor**: $y^a, x^a, h^a, w^a \in [0, 1]$

#### 1.1.1. Faster R-CNN

$$
\mathcal{L}_{box} = {1 \over N} \sum_{i=0}^{G_hG_wA} o_i^* \sum_{a \in \{y,x,h,w\}} H_{\delta}(\bar{a}_i^* - \bar{a}_i), \quad N=\mbox{# objects} \\
H_{\delta}(a) = \begin{cases}
{1 \over 2} a^2, & \mbox{if } |a|<\delta \\
\delta \left( |a| - {1 \over 2}\delta \right), & \mbox{otherwise}
\end{cases} \\
\bar{y}^* = (y^* - y^a) / h^a, \quad \bar{y} = (y - y^a) / h^a \ \rightarrow \ \bar{y}^* - \bar{y} =  (y^* - y) / h^a \\
\bar{x}^* = (x^* - x^a) / w^a, \quad \bar{x} = (x - x^a) / w^a \ \rightarrow \ \bar{x}^* - \bar{x} =  (x^* - x) / w^a \\
\bar{h}^* = \log(h^* / h^a), \quad \bar{h} = \log(h / h^a) \ \rightarrow \ \bar{h}^* - \bar{h} = \log(h^* / h) \\
\bar{w}^* = \log(w^* / w^a), \quad \bar{w} = \log(w / w^a)\ \rightarrow \ \bar{w}^* - \bar{w} = \log(w^* / w)
$$

Faster R-CNN에서는 Prediction과 GT 값을 직접 빼지 않고 $t_a$ 라는 중간 변수를 만들어 그 차이를 손실로 사용한다. 중간 변수를 만드는 주 목적은 anchor scale에 따른 손실의 불균형을 잡아주는 것이다. y, x 좌표 오차는 anchor의 h, w로 나누어서 손실 함수가 크기가 큰 객체에 편중되지 않도록 한다. h, w도 Prediction과 GT 사이의 비율을 log에 넣어서 자연스럽게 객체 크기에 무관한 손실 함수를 만들었다.

**Huber loss**는 regression 문제에서 자주 쓰이는 손실 함수인데, L1 norm과 L2 norm의 장점만 결합한 함수다. Faster R-CNN 논문에서는 *Robust loss function 또는 smooth L1* 이라고 표현했다.

|       | 장점                                                         | 단점                                                         |
| ----- | ------------------------------------------------------------ | ------------------------------------------------------------ |
| L1    | 오차에 대해 선형적이므로 이상치(outlier)에 덜 민감           | 0에서 미분이 불연속적<br />미분값이 상수라서 0에 정확히 수렴시키기 어려움 |
| L2    | 미분값이 오차에 비례하여 수렴속도 자동조절<br />0에서 미분이 연속적 | 오차의 제곱이므로 이상치(outlier)에 민감<br />이상치에서 너무 큰 손실 발생시켜 전체적인 학습 방해 |
| Huber | 큰 오차에 대해 선형적이므로 이상치(outlier)에 덜 민감<br />미분값이 오차에 비례하여 수렴속도 자동조절<br />0에서 미분이 연속적 | 연산량?                                                      |

다음은 세 가지 함수를 비교한 그래프다.

![huber](../assets/detector/huber_loss.png)



#### 1.1.2. YOLO (v1, 2016)

$$
\mathcal{L}_{box} = {1 \over N} \sum_{i=0}^{G_hG_wB} o_i^* \left\{
\left(y_i^* - y_i\right)^2 + \left(x_i^* - x_i\right)^2 + 
\left(\sqrt{h_i^*} - \sqrt{h_i}\right)^2 + \left(\sqrt{w_i^*} - \sqrt{w_i}\right)^2
\right\}, \quad N=\mbox{# objects}
$$

YOLO 초기 모델에서는 bounding box에 대한 손실 함수를 위와 같이 정의하였다. YOLO는 정해진 anchor box가 없고 단지 grid 마다 B(=2)개의 box를 예측하도록 만들었다. 그래서 anchor를 이용한 scale normalization을 못하지만 객체 크기가 큰 물체의 높이, 너비 오차에 의한 손실의 비중이 너무 커지지 않도록 너비, 높이에 square root를 씌웠다.

#### 1.1.3. YOLO v3

$$
\mathcal{L}_{box} = \sum_{s \in \left\{l, m, s\right\}} {1 \over N} \sum_{i=0}^{G_hG_wB} o_i^*
\sum_{a \in \{y,x,h,w\}} (\hat{a}_i^* - \hat{a}_i)^2
, \quad N=\mbox{# objects} \\

y^* = \sigma(\hat{y}^*) + c_y, \quad y = \sigma(\hat{y}) + c_y \\
x^* = \sigma(\hat{x}^*) + c_y, \quad x = \sigma(\hat{x}) + c_x \\
h^* = h^a * e^{\hat{h}^*}, \quad h = h^a * e^{\hat{h}} \\
w^* = w_a * e^{\hat{w}^*}, \quad w = w^a * e^{\hat{w}}
$$

YOLO v3에서는 세 가지 스케일의 feature map이 나오기 때문에 앞에 스케일에 대한 합이 추가되었다. 위 식에서 $\hat{a}$는 모델에서 마지막 convolution을 통과한 raw feature 값이고 $a$는 이를 bounding box의 크기나 좌표로 decode한 결과다. GT에서는 $a^*$가 주어진 값이고 $\hat{a}^*$는 decoding 과정을 역으로 계산하여 얻을 수 있다. 손실 함수에서는 bounding box의 크기, 좌표의 차이가 아니라 raw feature 값의 차이를 사용한다.   raw feature는 스케일의 영향도 받지 않고 $-\infty \sim +\infty$ 사이의 값을 가질 수 있기 때문에 큰 오차들을 빠르게 감소시킬 수 있다.  

#### 1.1.4. Complete IoU

검출 모델에서 실제 객체를 잘 검출했는지를 판단하는 기준은 GT box와 Predicted box 사이의 IoU(Intersection over Union)다. 결국 Bounding box loss의 목적은 GT box와 Predicted box를 일치시켜 IoU를 높이는 것이다. 그래서 YOLO 처럼 bounding box의 위치, 크기의 오차를 줄이기 보다는 IoU 자체를 손실 함수에 적용하는 방법이 연구되었다. 

1. IoU loss : IoU는 두 box(GT, Prediction)가 아예 겹치지 않으면 미분이 0이라서 학습이 되지 않는다.  
   $$
   IoU = {|B^{gt} \cap B| \over |B^{gt} \cup B|} \\
   \mathcal{L}_{IoU} = 1 - IoU
   $$
   
2. GIoU loss: 두 box가 떨어진 상태에서도 겹치는 부분이 생기도록 유도하는 penalty 함수를 추가한다. C는 두 box를 포함하는 최소의 box다. 
   $$
   \mathcal{L}_{IoU} = 1 - IoU + {|C - B^gt \cup B| \over |C|}
   $$
   
3. DIoU loss: 두 box의 중심점 좌표가 먼저 가까워지도록 유도한다. $\rho(\cdot)$은 Euclidean distance, $\mathbf{b}^{gt}, \mathbf{b}$는 각각 GT box와 Predicted box의 중심점이고 $c$는 위에서 말한 C box의 대각선 길이다.
   $$
   \mathcal{L}_{IoU} = 1 - IoU + {\rho^2(\mathbf{b}^{gt}, \mathbf{b}) \over c^2}
   $$
   
4. CIoU loss: DIoU loss에서 두 box 사이의 aspect ratio (가로/세로 비율)까지 비슷하게 맞추는 penalty를 추가하였다. (여기까지 하고 보니 box regression loss에 IoU loss를 더해준 것처럼 보인다.)  $v$는 arctan으로 계산되므로 범위가 $[0,\pi/2]$ 사이에 있으므로 앞에는 최대 값의 역수를 곱해서 $v$가 $[0,1]$ 범위에 들어오게 한다. $\alpha$는 IoU가 높을 수록 $v$에 의한 손실이 커지게 만든다. 즉, 초기에는 두 박스의 중심점을 맞추는데 집중하고 IoU가 어느정도 높아지면 aspect ratio에 높은 가중치를 두고 학습한다.
   $$
   \mathcal{L}_{IoU} = 1 - IoU + {\rho^2(\mathbf{b}^{gt}, \mathbf{b}) \over c^2} + \alpha v \\
   v = {4 \over \pi^2} \left(\arctan {w^* \over h^*} - \arctan {w \over h} \right)^2, \quad
   \alpha = {v \over 1-IoU+v}
   $$

![diou](../assets/detector/diou.png)

CIoU loss가 bounding box loss 중에는 가장 효과적이라고 알려져있기 때문에 본 강의에서 구현한 YOLO에서도 loss는 CIoU를 사용하였다.



### 1.2. Objectness



### 1.3. Categorical Probability

yolo v1 vs v3





## 2. Training Log





